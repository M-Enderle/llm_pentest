import chainlit as cl
from chainlit.input_widget import Select, Switch, TextInput
from dotenv import load_dotenv
from langchain.memory import ConversationBufferMemory

from chat.callbacks import CustomAsyncLangchainCallbackHandler
from llm_pentest.chains import MEMORY_KEY, create_agent
from llm_pentest.models import setup_gpt4, setup_gpt35, setup_lm_studio
from llm_pentest.tools import tools
from llm_pentest.utils import get_project_root

load_dotenv()


@cl.on_chat_start
async def main():
    await cl.ChatSettings(
        [
            TextInput(
                id="MachineIP",
                label="IP address of the target",
            ),
            Switch(
                id="Model",
                label="Use openAI?",
                initial=True,
            ),
        ]
    ).send()

    memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)
    agent = create_agent(setup_gpt4(), tools, memory=memory)

    cl.user_session.set("MachineIP", "")
    cl.user_session.set("agent", agent)
    cl.user_session.set("memory", memory)


@cl.on_settings_update
async def setup_agent(settings):
    memory = cl.user_session.get("memory")
    if not settings["Model"]:
        agent = create_agent(
            setup_lm_studio(), tools, settings["MachineIP"], memory=memory
        )
    else:
        agent = create_agent(setup_gpt4(), tools, settings["MachineIP"], memory=memory)

    cl.user_session.set("MachineIP", settings["MachineIP"])
    cl.user_session.set("agent", agent)


@cl.on_message
async def respond(message):
    if not cl.user_session.get("agent"):
        await cl.Message(content="Please setup the agent first").send()
        return

    agent = cl.user_session.get("agent")

    await agent.acall(
        {"input": message.content},
        callbacks=[
            CustomAsyncLangchainCallbackHandler(
                stream_final_answer=True,
            )
        ],
    )
