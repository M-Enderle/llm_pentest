import chainlit as cl
from dotenv import load_dotenv
from chainlit.input_widget import Select, TextInput, Switch
from langchain.memory import ConversationBufferMemory

from llm_pentest.utils import get_project_root
from llm_pentest.chains import create_agent, MEMORY_KEY
from llm_pentest.models import setup_lm_studio, setup_gpt35, setup_gpt4
from llm_pentest.tools import tools
from chat.callbacks import CustomAsyncLangchainCallbackHandler

load_dotenv()


@cl.on_chat_start
async def main():
    await cl.ChatSettings(
        [
            TextInput(
                id="MachineIP",
                label="IP address of the target",
            ),
            Switch(
                id="Model",
                label="Use openAI?",
                initial=True,
            )
        ]
    ).send()

    memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)
    agent = create_agent(setup_gpt4(), tools, memory=memory)

    cl.user_session.set("MachineIP", "")
    cl.user_session.set("agent", agent)
    cl.user_session.set("memory", memory)


@cl.on_settings_update
async def setup_agent(settings):
    if not settings["Model"]:
        agent = create_agent(setup_lm_studio(), tools, settings["MachineIP"])
    else:
        agent = create_agent(setup_gpt4(), tools, settings["MachineIP"])

    cl.user_session.set("MachineIP", settings["MachineIP"])
    cl.user_session.set("agent", agent)


@cl.on_message
async def respond(message):

    if not cl.user_session.get("agent"):
        await cl.Message(content="Please setup the agent first").send()
        return

    agent = cl.user_session.get("agent")

    await agent.acall(
            {"input": message.content},
            callbacks=[
                CustomAsyncLangchainCallbackHandler(
                    stream_final_answer=True,
                )
            ],
        )