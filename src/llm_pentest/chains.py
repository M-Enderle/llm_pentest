from langchain.agents import AgentExecutor, Tool, ZeroShotAgent, AgentExecutor, create_structured_chat_agent
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain_openai import OpenAI, ChatOpenAI
from langchain.tools import BaseTool, StructuredTool, tool
from langchain.schema import HumanMessage, SystemMessage
from langchain.cache import InMemoryCache
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.agents.format_scratchpad import format_to_openai_function_messages
from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser
from langchain.agents import AgentExecutor
from llm_pentest.utils import get_project_root
from langchain_community.tools.convert_to_openai import format_tool_to_openai_function


suffix = """
Begin!"

Question: {input}
{agent_scratchpad}
"""


def prompt_template(ip=None):

    system_message = open(
        get_project_root() / "llm_pentest" / "prompt_templates" / "main.txt"
    ).read()

    if ip:
        system_message += f"\n\nThe targets IP address is {ip}"

    return ChatPromptTemplate.from_messages(
        [
            (
                "system",
                system_message,
            ),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )


def create_agent(llm, tools, ip=None):

    llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])

    agent = (
        {
            "input": lambda x: x["input"],
            "agent_scratchpad": lambda x: format_to_openai_function_messages(
                x["intermediate_steps"]
            ),
        }
        | prompt_template(ip)
        | llm_with_tools
        | OpenAIFunctionsAgentOutputParser()
    )

    return AgentExecutor(agent=agent, tools=tools, verbose=True)


if __name__ == "__main__":
    print(prompt_template())